# ![CrowdTruth](http://crowdtruth.org/wp-content/uploads/2016/11/CrowdTruth.png)

[![PyPI version](https://badge.fury.io/py/CrowdTruth.svg)](https://badge.fury.io/py/CrowdTruth) [![Build Status](https://travis-ci.org/CrowdTruth/CrowdTruth-core.svg?branch=master)](https://travis-ci.org/CrowdTruth/CrowdTruth-core) [![codecov](https://codecov.io/gh/CrowdTruth/CrowdTruth-core/branch/master/graph/badge.svg)](https://codecov.io/gh/CrowdTruth/CrowdTruth-core) [![Scrutinizer Code Quality](https://scrutinizer-ci.com/g/CrowdTruth/CrowdTruth-core/badges/quality-score.png?b=master)](https://scrutinizer-ci.com/g/CrowdTruth/CrowdTruth-core/?branch=master) 

This library processes crowdsourcing results from Amazon Mechanical Turk and CrowdFlower following the CrowdTruth methodology. A full description of the metrics is available [in this paper](https://arxiv.org/abs/1808.06080). For more information see http://crowdtruth.org.

If you use this software in your research, please consider citing:

```
@article{CrowdTruth2,
  author    = {Anca Dumitrache and Oana Inel and Lora Aroyo and Benjamin Timmermans and Chris Welty},
  title     = {CrowdTruth 2.0: Quality Metrics for Crowdsourcing with Disagreement},
  year      = {2018},
  url       = {https://arxiv.org/abs/1808.06080},
}
```

Useful links:

* [Data](http://data.crowdtruth.org/) collected with CrowdTruth
* [Papers](http://crowdtruth.org/papers/) that use CrowdTruth
* Previous version [CrowdTruth v.1.0](https://github.com/CrowdTruth/CrowdTruth)


## Installation

To install the stable version from PyPI, install *pip* for your OS, then install package using:
```
pip install crowdtruth
```

To install the latest version from source, download the library and install it using:
```
python setup.py install
```

## Getting Started

### Data

Create a folder anywhere on your machine and fill it with raw result files from Amazon Mechanical Turk or CrowdFlower. These files should be unaltered `csv` files generated by either of the two platforms, and contain on each row a collected judgment. A folder may contain files from both platforms, but *the task must be the same*. All files in the same folder will be aggregated together, so if there are multiple tasks then the results for each should be put in separate sub folders.

### Tutorial

For the tutorial see https://github.com/CrowdTruth/CrowdTruth-core/blob/master/tutorial/tutorial.ipynb

### Configuration

Custom configuration can be added by creating a class that inherits from `DefaultConfig`. An example is shown in the tutorial above. Currently the following configuration options are available:

* `name`: a label to identify the type of configuration.
* `csv_file_separator`: a string containing the column separating character. If empty, `,` is used as separator.
* `inputColumns`: a list of columns that contain original input data. Setting this option allows you to filter out columns you are not interested in. If empty the columns will be identified automatically.
* `outputColumns`: a list of columns that contain judgments. Setting this option allows you to filter out columns you are not interested in. If empty the columns will be identified automatically.
* `annotation_separator`: a string containing the annotation separating character for the values in `outputColumns`, in case more than one annotation appears in one column. If empty, `,` is used as separator.
* `units`: a list of units to use. If empty all units are used.
* `workers`: a list of workers to use. If empty all workers are used.
* `jobs`: a list of jobs to use. If empty all jobs are used.
* `processJudgments(self, judgments):` a function to alter the judgments before they are processed in CrowdTruth. The `judgments` variable is a Pandas dataframe with all judgments of one input file. This function should always return the same dataframe, with only the input or output columns altered. The identified input columns are stored in `self.input.keys()` and the output columns in `self.output.keys()`.
* `processResults(self, results):` a function to alter the results after they are processed in CrowdTruth. This allows custom metrics to be run, or additional visualizations to be generated. The `results` variable is a dictionary with a Pandas dataframe for the *jobs*, *units*, *workers*, *judgments* and *annotations*. Each of these dataframes may be altered and new dataframes may be added to the dictionary. Each of the dataframes is saved as a tab in the `results.xlsx` file. Additionally, plots can be generated, which will be saved into the folder that is being processed.
